### 在165 ~ 175 Train起來後續又失效


# Trace 
TRACE_PATH = trace/target_MSR_mds_0.csv
TRACE_LENGTH = 1211034

# SSD 
LBA_BYTES = 4096
NUMS_OF_LBA_IN_PAGE = 4
NUMS_OF_PAGE_IN_BLOCK = 256
BLOCK_NUM = 500

# GC 
AUTO_GC_RATIO = 0.8
ACTIVE_GC_WAF_FULL_RATIO = 0.95
ACTIVE_GC_PERIOD = 1

# Reward
EPSILON = 31
EPSILON_RIGHT = 31
EPSILON_MIN = -38
EPSILON_DECAY = 35
ESTIMATED_BITS = 2

CHANGE_RATIO_REWARD = 1
MA_PERIOD = 100
CHANGE_RATIO_ALPHA = 500

COUNT_PENALTY = 0
COUNT_RATIO = 0.2
PENALTY_ALPHA = 0.0002
PENALTY_BASE = 1.18

# Input 
LBA_FREQ_PATH = ftl/pretrain/statistic/lba_frequency.csv

# Pretrain Model
INPUT_SIZE = 3
HIDDEN_SIZE = 100
ACTION_SIZE = 2
MODEL_WEIGHT_PATH = ftl/pretrain/weight/input_3_v1.pth

# DPQ
MAX_QUEUE = 10000
LR = 0.001
LR_MIN = 0.0001
LR_DECAY = 5000
EPSILON = 0.95
EPSILON_MIN = 0.05
EPSILON_DECAY = 100
GAMMA = 0.99

# Train
EPISODES = 200
MAX_STEP = 100000
WARM_UP_EPISODES = 1
BATCH_SIZE = 256
UPDATE_RATE = 2500

TRAIN_HISTORY_PATH = history/train/reimplement_220.png
TRAIN_MODEL_WEIGHT = dpq/weight/reimplement_220
SAVE_PERIOD = 1